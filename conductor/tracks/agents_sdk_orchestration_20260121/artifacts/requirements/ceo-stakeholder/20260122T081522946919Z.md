# Paired Subagent Review (ceo-stakeholder)

Provider: openai
Model: gpt-5.2-codex

---

- **Adopt Agents SDK primitives as the orchestration backbone** (Agent, Handoff, Guardrail, Session) to manage multi‑step workflows and tool loops automatically; **decision:** commit to Agents SDK rather than ad‑hoc orchestration for v1; **risk:** if we bypass SDK primitives, we’ll re‑implement context/tool management and increase failure modes (https://developers.openai.com/tracks/building-agents).  
- **Choose the orchestration style explicitly (LLM‑led vs code‑led) and document the mix**—LLM‑led for open‑ended tasks, code‑led for deterministic steps; **decision:** define which pipeline stages are LLM‑led vs scripted; **risk:** fully LLM‑led flows can be unpredictable and harder to test (https://medium.com/%40abdulkabirlive1/openai-agents-sdk-expert-level-guide-to-orchestration-44eeb67e1ec7).  
- **Enforce guardrails + structured outputs for every agent boundary** to ensure parseable responses and safety checks; **decision:** require JSON schema outputs for inter‑agent/tool calls; **risk:** unstructured outputs will break downstream automation and increase manual triage (https://developers.openai.com/tracks/building-agents).  
- **Design agent handoffs as modular specialist calls** (e.g., planner → tool‑executor → verifier) using `handoff(...)`; **decision:** build a clear agent graph and ownership; **risk:** missing handoff structure leads to monolithic prompts and brittle reasoning (https://medium.com/%40abdulkabirlive1/openai-agents-sdk-expert-level-guide-to-orchestration-44eeb67e1ec7).  
- **Centralize Anthropic routing via LiteLLM proxy** using `model="anthropic/claude-…"`, or `.../anthropic` passthrough endpoints; **decision:** standardize on LiteLLM gateway for all Claude traffic for cost/usage tracking; **risk:** direct Anthropic calls bypass logging, cost control, and governance (https://docs.litellm.ai/docs/providers/anthropic, https://docs.litellm.ai/docs/pass_through/anthropic_completion).  
- **Rely on LiteLLM’s automatic Anthropic parameter/schema mapping** (default `max_tokens`, `response_format → output_schema`, structured‑outputs headers); **decision:** document supported Claude models and schema expectations; **risk:** unsupported models may ignore schema → invalid JSON, so define fallback parsing (https://docs.litellm.ai/docs/providers/anthropic).  
- **Gate integration tests with pytest markers and config registration** (`@pytest.mark.integration` + `pytest.ini`/`pyproject.toml`) and exclude by default (`-m "not integration"`); **decision:** pick markers vs folder separation and enforce in CI; **risk:** unregistered markers cause warnings, and integration tests may run unintentionally in unit pipelines (https://docs.pytest.org/latest/example/markers.html, https://stackoverflow.com/questions/66315234/exclude-some-tests-by-default).

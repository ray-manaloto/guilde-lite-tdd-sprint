# Paired Subagent Review (ceo-stakeholder)

Provider: openai
Model: gpt-5.2-codex

---

- **Adopt Agents SDK primitives as the orchestration backbone (Agent, Handoff, Guardrail, Session)** to simplify multi-step workflows and tool management; **Decision:** codify these primitives in the spec so orchestration is standardized and debuggable across teams. **Risk:** ad‑hoc orchestration will fragment context/tool handling and inflate maintenance. (OpenAI Agents SDK track: https://developers.openai.com/tracks/building-agents)

- **Choose a mixed LLM‑led + code‑led orchestration style**: use LLM‑led planning for open‑ended tasks, but enforce code‑led steps for deterministic parts (e.g., external API calls, validation). **Decision:** explicitly define which tasks are delegated vs scripted in the plan. **Risk:** fully LLM‑led flows can be unpredictable; fully code‑led reduces adaptability. (https://medium.com/%40abdulkabirlive1/openai-agents-sdk-expert-level-guide-to-orchestration-44eeb67e1ec7)

- **Make Handoffs a first‑class pattern for modularity** (delegate to specialist agents). **Decision:** define handoff boundaries + required output schemas per specialist. **Risk:** without strict schemas, downstream parsing breaks; without handoffs, core agent becomes monolithic. (OpenAI Agents SDK & handoffs: https://developers.openai.com/tracks/building-agents)

- **Enforce guardrails + structured outputs** to control model behavior and parseability. **Decision:** specify JSON schema outputs for agent responses and guardrail steps for sensitive inputs. **Risk:** missing schema leads to unparseable outputs and brittle pipelines. (https://developers.openai.com/tracks/building-agents)

- **Route Anthropic models through LiteLLM with the `anthropic/` prefix or `/anthropic` base URL**; rely on LiteLLM for parameter mapping + structured output conversion. **Decision:** standardize the model naming convention and LiteLLM proxy URL in config. **Risk:** incorrect prefix or base URL will bypass proxy and lose centralized logging/cost tracking. (https://docs.litellm.ai/docs/providers/anthropic, https://docs.litellm.ai/docs/pass_through/anthropic_completion)

- **Leverage LiteLLM structured output support for Claude models** (automatic schema conversion + required headers). **Decision:** restrict structured‑output tests to supported Claude versions (e.g., Sonnet 4.5/Opus 4.1) and document fallback behavior. **Risk:** unsupported models ignore schema, breaking validation. (https://docs.litellm.ai/docs/providers/anthropic)

- **Gate integration tests via pytest markers and config**: define `integration` marker in `pytest.ini`/`pyproject.toml`, skip by default, run explicitly in CI when needed. **Decision:** include a CI job that runs `pytest -m integration` and keep unit default as `not integration`. **Risk:** accidental network tests in default runs will slow dev/CI and create flaky builds. (https://docs.pytest.org/latest/example/markers.html, https://stackoverflow.com/questions/66315234/exclude-some-tests-by-default)

These bullets should be encoded as spec decisions: orchestration primitives, handoff boundaries & schema requirements, LiteLLM routing conventions, structured output support constraints, and explicit pytest gating in CI.
